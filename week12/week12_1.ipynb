{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "995b2701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31a9fe63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0e85b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(boston.data, columns = boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb7ab5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max scaler \n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576d5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmaxscaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb8d253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxscaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a442527",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = minmaxscaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b79b537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57eab7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = pd.DataFrame(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "089748b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.040544</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.391378</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.349167</td>\n",
       "      <td>0.521869</td>\n",
       "      <td>0.676364</td>\n",
       "      <td>0.242381</td>\n",
       "      <td>0.371713</td>\n",
       "      <td>0.422208</td>\n",
       "      <td>0.622929</td>\n",
       "      <td>0.898568</td>\n",
       "      <td>0.301409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.096679</td>\n",
       "      <td>0.233225</td>\n",
       "      <td>0.251479</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.238431</td>\n",
       "      <td>0.134627</td>\n",
       "      <td>0.289896</td>\n",
       "      <td>0.191482</td>\n",
       "      <td>0.378576</td>\n",
       "      <td>0.321636</td>\n",
       "      <td>0.230313</td>\n",
       "      <td>0.230205</td>\n",
       "      <td>0.197049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131687</td>\n",
       "      <td>0.445392</td>\n",
       "      <td>0.433831</td>\n",
       "      <td>0.088259</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.175573</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.945730</td>\n",
       "      <td>0.144040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.507281</td>\n",
       "      <td>0.768280</td>\n",
       "      <td>0.188949</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.272901</td>\n",
       "      <td>0.686170</td>\n",
       "      <td>0.986232</td>\n",
       "      <td>0.265728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.041258</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.646628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.491770</td>\n",
       "      <td>0.586798</td>\n",
       "      <td>0.938980</td>\n",
       "      <td>0.369088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914122</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.998298</td>\n",
       "      <td>0.420116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     0.040544    0.113636    0.391378    0.069170    0.349167    0.521869   \n",
       "std      0.096679    0.233225    0.251479    0.253994    0.238431    0.134627   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000851    0.000000    0.173387    0.000000    0.131687    0.445392   \n",
       "50%      0.002812    0.000000    0.338343    0.000000    0.314815    0.507281   \n",
       "75%      0.041258    0.125000    0.646628    0.000000    0.491770    0.586798   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     0.676364    0.242381    0.371713    0.422208    0.622929    0.898568   \n",
       "std      0.289896    0.191482    0.378576    0.321636    0.230313    0.230205   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.433831    0.088259    0.130435    0.175573    0.510638    0.945730   \n",
       "50%      0.768280    0.188949    0.173913    0.272901    0.686170    0.986232   \n",
       "75%      0.938980    0.369088    1.000000    0.914122    0.808511    0.998298   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               12  \n",
       "count  506.000000  \n",
       "mean     0.301409  \n",
       "std      0.197049  \n",
       "min      0.000000  \n",
       "25%      0.144040  \n",
       "50%      0.265728  \n",
       "75%      0.420116  \n",
       "max      1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1953c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08942b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardscaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcd8a9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardscaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b14228dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled2 = standardscaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbba6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled2 = pd.DataFrame(X_scaled2, columns = boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b081f71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-5.616939e-17</td>\n",
       "      <td>6.319056e-17</td>\n",
       "      <td>-3.145486e-15</td>\n",
       "      <td>-2.106352e-17</td>\n",
       "      <td>2.752300e-15</td>\n",
       "      <td>-1.150770e-14</td>\n",
       "      <td>-1.137430e-15</td>\n",
       "      <td>7.582867e-16</td>\n",
       "      <td>5.616939e-17</td>\n",
       "      <td>5.616939e-17</td>\n",
       "      <td>-1.022283e-14</td>\n",
       "      <td>8.593916e-15</td>\n",
       "      <td>-5.897786e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "      <td>1.000990e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.197819e-01</td>\n",
       "      <td>-4.877224e-01</td>\n",
       "      <td>-1.557842e+00</td>\n",
       "      <td>-2.725986e-01</td>\n",
       "      <td>-1.465882e+00</td>\n",
       "      <td>-3.880249e+00</td>\n",
       "      <td>-2.335437e+00</td>\n",
       "      <td>-1.267069e+00</td>\n",
       "      <td>-9.828429e-01</td>\n",
       "      <td>-1.313990e+00</td>\n",
       "      <td>-2.707379e+00</td>\n",
       "      <td>-3.907193e+00</td>\n",
       "      <td>-1.531127e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.109696e-01</td>\n",
       "      <td>-4.877224e-01</td>\n",
       "      <td>-8.676906e-01</td>\n",
       "      <td>-2.725986e-01</td>\n",
       "      <td>-9.130288e-01</td>\n",
       "      <td>-5.686303e-01</td>\n",
       "      <td>-8.374480e-01</td>\n",
       "      <td>-8.056878e-01</td>\n",
       "      <td>-6.379618e-01</td>\n",
       "      <td>-7.675760e-01</td>\n",
       "      <td>-4.880391e-01</td>\n",
       "      <td>2.050715e-01</td>\n",
       "      <td>-7.994200e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.906665e-01</td>\n",
       "      <td>-4.877224e-01</td>\n",
       "      <td>-2.110985e-01</td>\n",
       "      <td>-2.725986e-01</td>\n",
       "      <td>-1.442174e-01</td>\n",
       "      <td>-1.084655e-01</td>\n",
       "      <td>3.173816e-01</td>\n",
       "      <td>-2.793234e-01</td>\n",
       "      <td>-5.230014e-01</td>\n",
       "      <td>-4.646726e-01</td>\n",
       "      <td>2.748590e-01</td>\n",
       "      <td>3.811865e-01</td>\n",
       "      <td>-1.812536e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.396560e-03</td>\n",
       "      <td>4.877224e-02</td>\n",
       "      <td>1.015999e+00</td>\n",
       "      <td>-2.725986e-01</td>\n",
       "      <td>5.986790e-01</td>\n",
       "      <td>4.827678e-01</td>\n",
       "      <td>9.067981e-01</td>\n",
       "      <td>6.623709e-01</td>\n",
       "      <td>1.661245e+00</td>\n",
       "      <td>1.530926e+00</td>\n",
       "      <td>8.065758e-01</td>\n",
       "      <td>4.336510e-01</td>\n",
       "      <td>6.030188e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.933931e+00</td>\n",
       "      <td>3.804234e+00</td>\n",
       "      <td>2.422565e+00</td>\n",
       "      <td>3.668398e+00</td>\n",
       "      <td>2.732346e+00</td>\n",
       "      <td>3.555044e+00</td>\n",
       "      <td>1.117494e+00</td>\n",
       "      <td>3.960518e+00</td>\n",
       "      <td>1.661245e+00</td>\n",
       "      <td>1.798194e+00</td>\n",
       "      <td>1.638828e+00</td>\n",
       "      <td>4.410519e-01</td>\n",
       "      <td>3.548771e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CRIM            ZN         INDUS          CHAS           NOX  \\\n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
       "mean  -5.616939e-17  6.319056e-17 -3.145486e-15 -2.106352e-17  2.752300e-15   \n",
       "std    1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00   \n",
       "min   -4.197819e-01 -4.877224e-01 -1.557842e+00 -2.725986e-01 -1.465882e+00   \n",
       "25%   -4.109696e-01 -4.877224e-01 -8.676906e-01 -2.725986e-01 -9.130288e-01   \n",
       "50%   -3.906665e-01 -4.877224e-01 -2.110985e-01 -2.725986e-01 -1.442174e-01   \n",
       "75%    7.396560e-03  4.877224e-02  1.015999e+00 -2.725986e-01  5.986790e-01   \n",
       "max    9.933931e+00  3.804234e+00  2.422565e+00  3.668398e+00  2.732346e+00   \n",
       "\n",
       "                 RM           AGE           DIS           RAD           TAX  \\\n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
       "mean  -1.150770e-14 -1.137430e-15  7.582867e-16  5.616939e-17  5.616939e-17   \n",
       "std    1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00  1.000990e+00   \n",
       "min   -3.880249e+00 -2.335437e+00 -1.267069e+00 -9.828429e-01 -1.313990e+00   \n",
       "25%   -5.686303e-01 -8.374480e-01 -8.056878e-01 -6.379618e-01 -7.675760e-01   \n",
       "50%   -1.084655e-01  3.173816e-01 -2.793234e-01 -5.230014e-01 -4.646726e-01   \n",
       "75%    4.827678e-01  9.067981e-01  6.623709e-01  1.661245e+00  1.530926e+00   \n",
       "max    3.555044e+00  1.117494e+00  3.960518e+00  1.661245e+00  1.798194e+00   \n",
       "\n",
       "            PTRATIO             B         LSTAT  \n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  \n",
       "mean  -1.022283e-14  8.593916e-15 -5.897786e-16  \n",
       "std    1.000990e+00  1.000990e+00  1.000990e+00  \n",
       "min   -2.707379e+00 -3.907193e+00 -1.531127e+00  \n",
       "25%   -4.880391e-01  2.050715e-01 -7.994200e-01  \n",
       "50%    2.748590e-01  3.811865e-01 -1.812536e-01  \n",
       "75%    8.065758e-01  4.336510e-01  6.030188e-01  \n",
       "max    1.638828e+00  4.410519e-01  3.548771e+00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59d77bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do so in once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e1ac1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled3 = standardscaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ca90355",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled3 = pd.DataFrame(X_scaled3, columns = boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cab5dbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CRIM    ZN  INDUS  CHAS   NOX    RM   AGE   DIS   RAD   TAX  PTRATIO  \\\n",
       "0    True  True   True  True  True  True  True  True  True  True     True   \n",
       "1    True  True   True  True  True  True  True  True  True  True     True   \n",
       "2    True  True   True  True  True  True  True  True  True  True     True   \n",
       "3    True  True   True  True  True  True  True  True  True  True     True   \n",
       "4    True  True   True  True  True  True  True  True  True  True     True   \n",
       "..    ...   ...    ...   ...   ...   ...   ...   ...   ...   ...      ...   \n",
       "501  True  True   True  True  True  True  True  True  True  True     True   \n",
       "502  True  True   True  True  True  True  True  True  True  True     True   \n",
       "503  True  True   True  True  True  True  True  True  True  True     True   \n",
       "504  True  True   True  True  True  True  True  True  True  True     True   \n",
       "505  True  True   True  True  True  True  True  True  True  True     True   \n",
       "\n",
       "        B  LSTAT  \n",
       "0    True   True  \n",
       "1    True   True  \n",
       "2    True   True  \n",
       "3    True   True  \n",
       "4    True   True  \n",
       "..    ...    ...  \n",
       "501  True   True  \n",
       "502  True   True  \n",
       "503  True   True  \n",
       "504  True   True  \n",
       "505  True   True  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled3 == X_scaled2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32167dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a570edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaf459b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22405476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'breast_cancer.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8734879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fed55f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbcd2b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = pd.DataFrame(cancer.data, columns = cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef7147ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df05eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(cancer.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18898393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "564    0\n",
       "565    0\n",
       "566    0\n",
       "567    0\n",
       "568    1\n",
       "Length: 569, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b1fe1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f45f9c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(T,y, test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "856d6eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30) (171, 30) (398,) (171,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "403b8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df0a98ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ef30d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = sc.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17f46127",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fed0d4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.82895561, -1.03841826, -0.86206574, ..., -1.51467576,\n",
       "        -0.09484438, -0.53072076],\n",
       "       [-1.26079299, -0.8385321 , -1.2735596 , ..., -0.97153965,\n",
       "        -0.05307879, -0.08303331],\n",
       "       [ 0.97227591, -0.01877424,  0.95883624, ...,  1.24191108,\n",
       "         0.08667531, -0.26518355],\n",
       "       ...,\n",
       "       [ 1.41041331,  1.2142314 ,  1.50860537, ...,  2.1035875 ,\n",
       "         2.88497009,  1.22099683],\n",
       "       [ 1.72827769,  0.03063582,  1.73767584, ...,  1.60586827,\n",
       "         0.25373769, -0.142173  ],\n",
       "       [-0.9148649 ,  0.43714588, -0.84040817, ...,  0.4408942 ,\n",
       "         0.1445046 ,  0.76325564]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26fe3ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "325dfaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b26c664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1000, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3748fcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, solver='liblinear')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5572f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ef7f3a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171,) (171, 30)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape,X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1eb4ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d50e5075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     166\n",
       "False      5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Y_test == y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0bb9f190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9707602339181286\n"
     ]
    }
   ],
   "source": [
    "print(float(166/171))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cabdadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa47ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "accc70ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e55a50b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 64,   4],\n",
       "       [  1, 102]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dea5a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diag : correctly predicted values\n",
    "# off diag : incorrectly predicted values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbdef67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(Y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19026e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 4 1 102\n"
     ]
    }
   ],
   "source": [
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d05155e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af177896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9707602339181286"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a20d9f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((171,), (171,))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4cfab3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as prfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31c45ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.98461538, 0.96226415]),\n",
       " array([0.94117647, 0.99029126]),\n",
       " array([0.96240602, 0.97607656]),\n",
       " array([ 68, 103]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prfs(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "508554c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function precision_recall_fscore_support in module sklearn.metrics._classification:\n",
      "\n",
      "precision_recall_fscore_support(y_true, y_pred, *, beta=1.0, labels=None, pos_label=1, average=None, warn_for=('precision', 'recall', 'f-score'), sample_weight=None, zero_division='warn')\n",
      "    Compute precision, recall, F-measure and support for each class.\n",
      "    \n",
      "    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\n",
      "    true positives and ``fp`` the number of false positives. The precision is\n",
      "    intuitively the ability of the classifier not to label as positive a sample\n",
      "    that is negative.\n",
      "    \n",
      "    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\n",
      "    true positives and ``fn`` the number of false negatives. The recall is\n",
      "    intuitively the ability of the classifier to find all the positive samples.\n",
      "    \n",
      "    The F-beta score can be interpreted as a weighted harmonic mean of\n",
      "    the precision and recall, where an F-beta score reaches its best\n",
      "    value at 1 and worst score at 0.\n",
      "    \n",
      "    The F-beta score weights recall more than precision by a factor of\n",
      "    ``beta``. ``beta == 1.0`` means recall and precision are equally important.\n",
      "    \n",
      "    The support is the number of occurrences of each class in ``y_true``.\n",
      "    \n",
      "    If ``pos_label is None`` and in binary classification, this function\n",
      "    returns the average precision, recall and F-measure if ``average``\n",
      "    is one of ``'micro'``, ``'macro'``, ``'weighted'`` or ``'samples'``.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "        Ground truth (correct) target values.\n",
      "    \n",
      "    y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "        Estimated targets as returned by a classifier.\n",
      "    \n",
      "    beta : float, default=1.0\n",
      "        The strength of recall versus precision in the F-score.\n",
      "    \n",
      "    labels : array-like, default=None\n",
      "        The set of labels to include when ``average != 'binary'``, and their\n",
      "        order if ``average is None``. Labels present in the data can be\n",
      "        excluded, for example to calculate a multiclass average ignoring a\n",
      "        majority negative class, while labels not present in the data will\n",
      "        result in 0 components in a macro average. For multilabel targets,\n",
      "        labels are column indices. By default, all labels in ``y_true`` and\n",
      "        ``y_pred`` are used in sorted order.\n",
      "    \n",
      "    pos_label : str or int, default=1\n",
      "        The class to report if ``average='binary'`` and the data is binary.\n",
      "        If the data are multiclass or multilabel, this will be ignored;\n",
      "        setting ``labels=[pos_label]`` and ``average != 'binary'`` will report\n",
      "        scores for that label only.\n",
      "    \n",
      "    average : {'binary', 'micro', 'macro', 'samples','weighted'},             default=None\n",
      "        If ``None``, the scores for each class are returned. Otherwise, this\n",
      "        determines the type of averaging performed on the data:\n",
      "    \n",
      "        ``'binary'``:\n",
      "            Only report results for the class specified by ``pos_label``.\n",
      "            This is applicable only if targets (``y_{true,pred}``) are binary.\n",
      "        ``'micro'``:\n",
      "            Calculate metrics globally by counting the total true positives,\n",
      "            false negatives and false positives.\n",
      "        ``'macro'``:\n",
      "            Calculate metrics for each label, and find their unweighted\n",
      "            mean.  This does not take label imbalance into account.\n",
      "        ``'weighted'``:\n",
      "            Calculate metrics for each label, and find their average weighted\n",
      "            by support (the number of true instances for each label). This\n",
      "            alters 'macro' to account for label imbalance; it can result in an\n",
      "            F-score that is not between precision and recall.\n",
      "        ``'samples'``:\n",
      "            Calculate metrics for each instance, and find their average (only\n",
      "            meaningful for multilabel classification where this differs from\n",
      "            :func:`accuracy_score`).\n",
      "    \n",
      "    warn_for : tuple or set, for internal use\n",
      "        This determines which warnings will be made in the case that this\n",
      "        function is being used to return only one of its metrics.\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "    \n",
      "    zero_division : \"warn\", 0 or 1, default=\"warn\"\n",
      "        Sets the value to return when there is a zero division:\n",
      "           - recall: when there are no positive labels\n",
      "           - precision: when there are no positive predictions\n",
      "           - f-score: both\n",
      "    \n",
      "        If set to \"warn\", this acts as 0, but warnings are also raised.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    precision : float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "    \n",
      "    recall : float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "    \n",
      "    fbeta_score : float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "    \n",
      "    support : None (if average is not None) or array of int, shape =        [n_unique_labels]\n",
      "        The number of occurrences of each label in ``y_true``.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    When ``true positive + false positive == 0``, precision is undefined.\n",
      "    When ``true positive + false negative == 0``, recall is undefined.\n",
      "    In such cases, by default the metric will be set to 0, as will f-score,\n",
      "    and ``UndefinedMetricWarning`` will be raised. This behavior can be\n",
      "    modified with ``zero_division``.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Precision and recall\n",
      "           <https://en.wikipedia.org/wiki/Precision_and_recall>`_.\n",
      "    \n",
      "    .. [2] `Wikipedia entry for the F1-score\n",
      "           <https://en.wikipedia.org/wiki/F1_score>`_.\n",
      "    \n",
      "    .. [3] `Discriminative Methods for Multi-labeled Classification Advances\n",
      "           in Knowledge Discovery and Data Mining (2004), pp. 22-30 by Shantanu\n",
      "           Godbole, Sunita Sarawagi\n",
      "           <http://www.godbole.net/shantanu/pubs/multilabelsvm-pakdd04.pdf>`_.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.metrics import precision_recall_fscore_support\n",
      "    >>> y_true = np.array(['cat', 'dog', 'pig', 'cat', 'dog', 'pig'])\n",
      "    >>> y_pred = np.array(['cat', 'pig', 'dog', 'cat', 'cat', 'dog'])\n",
      "    >>> precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
      "    (0.22..., 0.33..., 0.26..., None)\n",
      "    >>> precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
      "    (0.33..., 0.33..., 0.33..., None)\n",
      "    >>> precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
      "    (0.22..., 0.33..., 0.26..., None)\n",
      "    \n",
      "    It is possible to compute per-label precisions, recalls, F1-scores and\n",
      "    supports instead of averaging:\n",
      "    \n",
      "    >>> precision_recall_fscore_support(y_true, y_pred, average=None,\n",
      "    ... labels=['pig', 'dog', 'cat'])\n",
      "    (array([0.        , 0.        , 0.66...]),\n",
      "     array([0., 0., 1.]), array([0. , 0. , 0.8]),\n",
      "     array([2, 2, 2]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(prfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "309d0af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9622641509433962, 0.9902912621359223)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp / (tp+fp), tp/(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb1613cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9760765550239234"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*tp) / (2*tp + fn + fp) # f1 score? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21052bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report as C_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f117e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of all necessary metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d854919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96        68\n",
      "           1       0.96      0.99      0.98       103\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.97      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(C_R(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d6870ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = lr.predict_proba(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6984c8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.00393691e-016],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 2.17663796e-039],\n",
       "       [1.88365938e-004, 9.99811634e-001],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.01321174e-011, 1.00000000e+000],\n",
       "       [3.96777483e-006, 9.99996032e-001],\n",
       "       [5.95550463e-003, 9.94044495e-001],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.03240513e-037],\n",
       "       [1.00000000e+000, 3.97732640e-027],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.61331361e-021],\n",
       "       [9.88241872e-003, 9.90117581e-001],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [4.72288875e-013, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.72576176e-010, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.18173094e-074],\n",
       "       [1.00000000e+000, 1.65993994e-019],\n",
       "       [4.14166701e-010, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 5.58019670e-027],\n",
       "       [1.00000000e+000, 9.08098840e-017],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 4.54555116e-030],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.48860205e-015],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [3.97459843e-014, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.66025517e-023],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [2.59228273e-002, 9.74077173e-001],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [8.65005412e-009, 9.99999991e-001],\n",
       "       [1.00000000e+000, 3.00874802e-031],\n",
       "       [1.00000000e+000, 1.29225108e-016],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 2.01207800e-024],\n",
       "       [7.43157221e-001, 2.56842779e-001],\n",
       "       [1.00000000e+000, 3.24121032e-020],\n",
       "       [1.80402582e-010, 1.00000000e+000],\n",
       "       [1.00000000e+000, 6.05231141e-046],\n",
       "       [1.00000000e+000, 3.13343834e-101],\n",
       "       [1.43776394e-002, 9.85622361e-001],\n",
       "       [1.00000000e+000, 3.19370550e-031],\n",
       "       [1.00000000e+000, 5.54180297e-021],\n",
       "       [1.00000000e+000, 4.91300057e-090],\n",
       "       [1.02345713e-002, 9.89765429e-001],\n",
       "       [8.92112264e-008, 9.99999911e-001],\n",
       "       [2.22044605e-016, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.20557079e-014],\n",
       "       [8.88959351e-010, 9.99999999e-001],\n",
       "       [1.00000000e+000, 8.43531865e-054],\n",
       "       [1.00000000e+000, 1.41888157e-070],\n",
       "       [4.37609694e-003, 9.95623903e-001],\n",
       "       [1.00000000e+000, 1.89924876e-038],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.84644744e-010, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 4.14061840e-075],\n",
       "       [6.66133815e-016, 1.00000000e+000],\n",
       "       [4.44089210e-016, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.17271573e-010],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [9.99999881e-001, 1.19479031e-007],\n",
       "       [8.08422218e-011, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.48538229e-020],\n",
       "       [7.54951657e-015, 1.00000000e+000],\n",
       "       [4.85926890e-006, 9.99995141e-001],\n",
       "       [1.00000000e+000, 2.79079714e-060],\n",
       "       [1.00000000e+000, 2.00460531e-024],\n",
       "       [1.00000000e+000, 2.59098020e-015],\n",
       "       [1.17166544e-003, 9.98828335e-001],\n",
       "       [1.00000000e+000, 9.32299188e-027],\n",
       "       [1.00000000e+000, 3.04325410e-037],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [3.72990527e-012, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 3.99057847e-028],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 2.79452539e-028],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 6.99618595e-019],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [6.68354261e-014, 1.00000000e+000],\n",
       "       [1.00000000e+000, 7.09734866e-061],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.62092562e-014, 1.00000000e+000],\n",
       "       [3.99680289e-015, 1.00000000e+000],\n",
       "       [2.59723132e-010, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.57651669e-014, 1.00000000e+000],\n",
       "       [1.99840144e-015, 1.00000000e+000],\n",
       "       [1.20658665e-007, 9.99999879e-001],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 5.88060497e-038],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.77731662e-034],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 2.62621616e-044],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.48769885e-014, 1.00000000e+000],\n",
       "       [1.78928872e-010, 1.00000000e+000],\n",
       "       [2.22044605e-016, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [6.95177249e-011, 1.00000000e+000],\n",
       "       [1.00000000e+000, 3.52148293e-051],\n",
       "       [2.30749656e-008, 9.99999977e-001],\n",
       "       [1.00000000e+000, 1.35586014e-026],\n",
       "       [1.00000000e+000, 1.07326618e-014],\n",
       "       [1.55475632e-012, 1.00000000e+000],\n",
       "       [6.72503830e-010, 9.99999999e-001],\n",
       "       [1.00000000e+000, 6.85879963e-076],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 5.57118927e-027],\n",
       "       [1.00000000e+000, 7.44644834e-026],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.99840144e-015, 1.00000000e+000],\n",
       "       [6.66133815e-016, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.18065198e-032],\n",
       "       [1.00000000e+000, 1.26056826e-038],\n",
       "       [1.00000000e+000, 1.43035070e-043],\n",
       "       [4.44966286e-011, 1.00000000e+000],\n",
       "       [1.00000000e+000, 4.92309891e-090],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 4.25196605e-046],\n",
       "       [1.30998643e-002, 9.86900136e-001],\n",
       "       [1.00000000e+000, 1.19869284e-027],\n",
       "       [1.00000000e+000, 1.78131096e-034],\n",
       "       [6.93062163e-009, 9.99999993e-001],\n",
       "       [1.00000000e+000, 3.79685270e-089],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 2.43904718e-029],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.43152157e-012, 1.00000000e+000],\n",
       "       [1.00000000e+000, 1.55388122e-018],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [1.00000000e+000, 5.67154274e-013],\n",
       "       [1.00000000e+000, 1.08274736e-060],\n",
       "       [1.00000000e+000, 1.24296684e-021],\n",
       "       [9.19935205e-002, 9.08006479e-001],\n",
       "       [5.04344386e-006, 9.99994957e-001],\n",
       "       [3.26440492e-008, 9.99999967e-001],\n",
       "       [1.00000000e+000, 2.48981646e-016],\n",
       "       [9.60060753e-009, 9.99999990e-001],\n",
       "       [2.24265051e-014, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [0.00000000e+000, 1.00000000e+000],\n",
       "       [4.64381066e-004, 9.99535619e-001],\n",
       "       [1.00000000e+000, 4.42513501e-029],\n",
       "       [1.00000000e+000, 1.04306140e-030],\n",
       "       [1.00000000e+000, 1.06126726e-013]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4af9272e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probs[:,0] + y_pred_probs[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c0bab88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd5c11e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function roc_curve in module sklearn.metrics._ranking:\n",
      "\n",
      "roc_curve(y_true, y_score, *, pos_label=None, sample_weight=None, drop_intermediate=True)\n",
      "    Compute Receiver operating characteristic (ROC).\n",
      "    \n",
      "    Note: this implementation is restricted to the binary classification task.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <roc_metrics>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : ndarray of shape (n_samples,)\n",
      "        True binary labels. If labels are not either {-1, 1} or {0, 1}, then\n",
      "        pos_label should be explicitly given.\n",
      "    \n",
      "    y_score : ndarray of shape (n_samples,)\n",
      "        Target scores, can either be probability estimates of the positive\n",
      "        class, confidence values, or non-thresholded measure of decisions\n",
      "        (as returned by \"decision_function\" on some classifiers).\n",
      "    \n",
      "    pos_label : int or str, default=None\n",
      "        The label of the positive class.\n",
      "        When ``pos_label=None``, if `y_true` is in {-1, 1} or {0, 1},\n",
      "        ``pos_label`` is set to 1, otherwise an error will be raised.\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "    \n",
      "    drop_intermediate : bool, default=True\n",
      "        Whether to drop some suboptimal thresholds which would not appear\n",
      "        on a plotted ROC curve. This is useful in order to create lighter\n",
      "        ROC curves.\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "           parameter *drop_intermediate*.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    fpr : ndarray of shape (>2,)\n",
      "        Increasing false positive rates such that element i is the false\n",
      "        positive rate of predictions with score >= `thresholds[i]`.\n",
      "    \n",
      "    tpr : ndarray of shape (>2,)\n",
      "        Increasing true positive rates such that element `i` is the true\n",
      "        positive rate of predictions with score >= `thresholds[i]`.\n",
      "    \n",
      "    thresholds : ndarray of shape = (n_thresholds,)\n",
      "        Decreasing thresholds on the decision function used to compute\n",
      "        fpr and tpr. `thresholds[0]` represents no instances being predicted\n",
      "        and is arbitrarily set to `max(y_score) + 1`.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    RocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic\n",
      "        (ROC) curve given an estimator and some data.\n",
      "    RocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic\n",
      "        (ROC) curve given the true and predicted values.\n",
      "    det_curve: Compute error rates for different probability thresholds.\n",
      "    roc_auc_score : Compute the area under the ROC curve.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Since the thresholds are sorted from low to high values, they\n",
      "    are reversed upon returning them to ensure they correspond to both ``fpr``\n",
      "    and ``tpr``, which are sorted in reversed order during their calculation.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Receiver operating characteristic\n",
      "            <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n",
      "    \n",
      "    .. [2] Fawcett T. An introduction to ROC analysis[J]. Pattern Recognition\n",
      "           Letters, 2006, 27(8):861-874.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn import metrics\n",
      "    >>> y = np.array([1, 1, 2, 2])\n",
      "    >>> scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
      "    >>> fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)\n",
      "    >>> fpr\n",
      "    array([0. , 0. , 0.5, 0.5, 1. ])\n",
      "    >>> tpr\n",
      "    array([0. , 0.5, 0.5, 1. , 1. ])\n",
      "    >>> thresholds\n",
      "    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(roc_curve) # Receiver operating Characteristic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8128607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(Y_test, y_pred_probs[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "01e68c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01470588, 0.01470588, 0.01470588, 0.01470588,\n",
       "       0.01470588, 0.02941176, 0.02941176, 0.04411765, 0.04411765,\n",
       "       0.05882353, 0.05882353, 1.        ])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fda61495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.51456311, 0.53398058, 0.54368932, 0.58252427,\n",
       "       0.69902913, 0.69902913, 0.91262136, 0.91262136, 0.97087379,\n",
       "       0.97087379, 1.        , 1.        ])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d1fe084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x174394850>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr,tpr, label='ROC curve')\n",
    "plt.plot([0,1], [0, 1]) # diagonal comparison\n",
    "plt.xlabel('False Positive rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3456a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(Y_test, y_pred_probs[:, 1]) # first class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a7ccc6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9829383209594518\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6239f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "06a87a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eb416978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de524032",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d103d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2908724c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "772051de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "09377a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5],\n",
       "       [4.9, 3. ],\n",
       "       [4.7, 3.2],\n",
       "       [4.6, 3.1],\n",
       "       [5. , 3.6],\n",
       "       [5.4, 3.9],\n",
       "       [4.6, 3.4],\n",
       "       [5. , 3.4],\n",
       "       [4.4, 2.9],\n",
       "       [4.9, 3.1],\n",
       "       [5.4, 3.7],\n",
       "       [4.8, 3.4],\n",
       "       [4.8, 3. ],\n",
       "       [4.3, 3. ],\n",
       "       [5.8, 4. ],\n",
       "       [5.7, 4.4],\n",
       "       [5.4, 3.9],\n",
       "       [5.1, 3.5],\n",
       "       [5.7, 3.8],\n",
       "       [5.1, 3.8],\n",
       "       [5.4, 3.4],\n",
       "       [5.1, 3.7],\n",
       "       [4.6, 3.6],\n",
       "       [5.1, 3.3],\n",
       "       [4.8, 3.4],\n",
       "       [5. , 3. ],\n",
       "       [5. , 3.4],\n",
       "       [5.2, 3.5],\n",
       "       [5.2, 3.4],\n",
       "       [4.7, 3.2],\n",
       "       [4.8, 3.1],\n",
       "       [5.4, 3.4],\n",
       "       [5.2, 4.1],\n",
       "       [5.5, 4.2],\n",
       "       [4.9, 3.1],\n",
       "       [5. , 3.2],\n",
       "       [5.5, 3.5],\n",
       "       [4.9, 3.6],\n",
       "       [4.4, 3. ],\n",
       "       [5.1, 3.4],\n",
       "       [5. , 3.5],\n",
       "       [4.5, 2.3],\n",
       "       [4.4, 3.2],\n",
       "       [5. , 3.5],\n",
       "       [5.1, 3.8],\n",
       "       [4.8, 3. ],\n",
       "       [5.1, 3.8],\n",
       "       [4.6, 3.2],\n",
       "       [5.3, 3.7],\n",
       "       [5. , 3.3],\n",
       "       [7. , 3.2],\n",
       "       [6.4, 3.2],\n",
       "       [6.9, 3.1],\n",
       "       [5.5, 2.3],\n",
       "       [6.5, 2.8],\n",
       "       [5.7, 2.8],\n",
       "       [6.3, 3.3],\n",
       "       [4.9, 2.4],\n",
       "       [6.6, 2.9],\n",
       "       [5.2, 2.7],\n",
       "       [5. , 2. ],\n",
       "       [5.9, 3. ],\n",
       "       [6. , 2.2],\n",
       "       [6.1, 2.9],\n",
       "       [5.6, 2.9],\n",
       "       [6.7, 3.1],\n",
       "       [5.6, 3. ],\n",
       "       [5.8, 2.7],\n",
       "       [6.2, 2.2],\n",
       "       [5.6, 2.5],\n",
       "       [5.9, 3.2],\n",
       "       [6.1, 2.8],\n",
       "       [6.3, 2.5],\n",
       "       [6.1, 2.8],\n",
       "       [6.4, 2.9],\n",
       "       [6.6, 3. ],\n",
       "       [6.8, 2.8],\n",
       "       [6.7, 3. ],\n",
       "       [6. , 2.9],\n",
       "       [5.7, 2.6],\n",
       "       [5.5, 2.4],\n",
       "       [5.5, 2.4],\n",
       "       [5.8, 2.7],\n",
       "       [6. , 2.7],\n",
       "       [5.4, 3. ],\n",
       "       [6. , 3.4],\n",
       "       [6.7, 3.1],\n",
       "       [6.3, 2.3],\n",
       "       [5.6, 3. ],\n",
       "       [5.5, 2.5],\n",
       "       [5.5, 2.6],\n",
       "       [6.1, 3. ],\n",
       "       [5.8, 2.6],\n",
       "       [5. , 2.3],\n",
       "       [5.6, 2.7],\n",
       "       [5.7, 3. ],\n",
       "       [5.7, 2.9],\n",
       "       [6.2, 2.9],\n",
       "       [5.1, 2.5],\n",
       "       [5.7, 2.8],\n",
       "       [6.3, 3.3],\n",
       "       [5.8, 2.7],\n",
       "       [7.1, 3. ],\n",
       "       [6.3, 2.9],\n",
       "       [6.5, 3. ],\n",
       "       [7.6, 3. ],\n",
       "       [4.9, 2.5],\n",
       "       [7.3, 2.9],\n",
       "       [6.7, 2.5],\n",
       "       [7.2, 3.6],\n",
       "       [6.5, 3.2],\n",
       "       [6.4, 2.7],\n",
       "       [6.8, 3. ],\n",
       "       [5.7, 2.5],\n",
       "       [5.8, 2.8],\n",
       "       [6.4, 3.2],\n",
       "       [6.5, 3. ],\n",
       "       [7.7, 3.8],\n",
       "       [7.7, 2.6],\n",
       "       [6. , 2.2],\n",
       "       [6.9, 3.2],\n",
       "       [5.6, 2.8],\n",
       "       [7.7, 2.8],\n",
       "       [6.3, 2.7],\n",
       "       [6.7, 3.3],\n",
       "       [7.2, 3.2],\n",
       "       [6.2, 2.8],\n",
       "       [6.1, 3. ],\n",
       "       [6.4, 2.8],\n",
       "       [7.2, 3. ],\n",
       "       [7.4, 2.8],\n",
       "       [7.9, 3.8],\n",
       "       [6.4, 2.8],\n",
       "       [6.3, 2.8],\n",
       "       [6.1, 2.6],\n",
       "       [7.7, 3. ],\n",
       "       [6.3, 3.4],\n",
       "       [6.4, 3.1],\n",
       "       [6. , 3. ],\n",
       "       [6.9, 3.1],\n",
       "       [6.7, 3.1],\n",
       "       [6.9, 3.1],\n",
       "       [5.8, 2.7],\n",
       "       [6.8, 3.2],\n",
       "       [6.7, 3.3],\n",
       "       [6.7, 3. ],\n",
       "       [6.3, 2.5],\n",
       "       [6.5, 3. ],\n",
       "       [6.2, 3.4],\n",
       "       [5.9, 3. ]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5602b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', C=1000)\n",
    "# lbfgn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b48a1b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000, multi_class='multinomial')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "21df423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ead62e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_light = ListedColormap(['orange','cyan', 'cornflowerblue'])\n",
    "cmap_bold = ListedColormap(['darkorange','darkblue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e26bda28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '3-Class Classification with Softmax Regressions')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA+JUlEQVR4nO3dd3jUVdbA8e9JAwIhCUV6FUQEFBF7x97Q3bUtVizYsKKuur72srZdu67LYhdZURRREZQmiiggVUBBuvSWhBDSzvvH/cUMYWYyk8xkMpPzeR4eMnduzj3TTu7cXxNVxRhjTPxLinUCxhhjIsMKujHGJAgr6MYYkyCsoBtjTIKwgm6MMQnCCroxxiQIK+hhEJEHROSdWOdRRkTeEJFHohg/T0Q6ez83EJFPRWS7iHwgIheJyLgojHm0iCyOdNxIjS8iHUVERSSlBnLpJiKzRSRXRG6K9nh1RazfY9GU0AVdRN4RkbUikiMiv4jIVSH8zgARmeEVs7Ui8oWIHFUT+frJRUTkJhGZLyI7RGS1V0x71cT4qtpIVX/zbp4LtACaqup5qvquqp5c3TG84tjFZ8xvVLVbdeNWVcXxRWS5iJxY1Xgi0lZEPhSRTd4fw/kicnmIv34nMFFVM1T1+ermEkleLju9z8k6b3LRKNZ5hSLW77FoSuiCDjwOdFTVxkB/4BEROShQZxG5DXgWeAxXvNoDLwNnRz9Vv54DbgZuApoA+wAfA2fEIJcOwC+qWhyDsePZ28Aq3PPXFLgEWB/i73YAFkQpr0g4S1UbAb2BA4G7Iz1ATXwTSiiqWif+Ad2AtcD5Ae7PBPKA84LEeAB4x+f2B8A6YDswBejhc9/pwM9ALrAGuN1rbwaMAbYBW4BvgCQ/Y3UFSoBDguTzBvCI93O2F3cjsNX7ua1P38uB37x8lgEXee1dgMneY9gEjPD5HfXufxAoBIq85+hKL95Un749gPHeY1oP3OO1HwJM8x7vWuBFIM27b4o3xg4v7gXAccBqn7jdgUne7y8A+ld4/C8Bn3mPazqwd4Dn6k1giPdzG2/cG7zbe3t5J/mOjyvGpcBOL787gY7e714GrPSes78HeY3ygN5B7u/vPa5t3uPs7rVP8F7/Ai/G8CC5DMT90dgKXAscDMz1Yr7oM9beXtzNXt7vAlkVnoM+3u3WuPfScQHyXg6c6HP7SeAzn9uHAd95OczxjQN08l77XOAr7zV8x7uv7DFd6T2/U7z2K4CF3mP8EujgtQvwL2ADkAPMA3pW8hn84zWuznss2Ngxq3OxHLxGHqCbYed7b5JZQKMA/U4FioGUILEeYPeCfgWQAdTDzexn+9y3Fjja+znb54PyOPAqkOr9OxoQP2NdC6yo5LG9QXlBbwr8BUj3cvoA+Ni7r6H3huvm3W6F98cHVyj+jitm9YGjfOIr0CXAY78cr6B7460FhngxMoBDvfsOwn24U3Af1oXALf7G8G7/8WHznp8lwD1AGtDP+1B183n8m3F/NFJwBer9AM/VFcCn3s8DgKV4f7y8+z6pOL53ezm7F66OXs7/ARoABwC78Aqxn3G/Ar4FLgTaV7hvH9wfs5O8x3qn93jL/uBNAq4KIZdXvef9ZNwfgI+BvXB/uDYAx3r9u3hj1QOa44rqsz7xrsYVwHRc0Xw6yHvvj1yAtrhi9px3u433upyOe1+d5N1u7t0/DXjae02Pwr03Kxb0t3Dv2wa4b8hLcIU3BbgX+M7rfwowE8jCFdjuQKtKPoN/vMZU4z0WbOxY/Uv0JRdU9XpcgTka+Aj34fOnKbBJw1hSUNVhqpqrqrtwBe8AEcn07i4C9hORxqq6VVVn+bS3ws0witSt5/k7oU5T3Bsy1Fw2q+qHqpqvqrnAo8CxPl1KgZ4i0kBV16pq2Vf5ItxX+9aqWqCqU0Md08eZwDpVfcaLkauq0728Zqrq96parKrLgX9XyCuYw4BGwD9UtVBVJ+C+efzVp88oVf3Be93exX3992cycJSIJAHH4GaUR3r3HevdH44HVXWnqs7BzUAPCNDvPNy3sP8DlnkbOQ/27rsAN6sdr6pFuCLXADgizFwe9p73cbg/EMNVdYOqrvHGPhBAVZd4Y+1S1Y3AP/F5LVT1P7jiNh33Hv17JeN+LCK5uG8HG4D7vfaLgc9V9XNVLVXV8cAM4HQRaY/7BnGf95pOBUb7if2Aqu5Q1Z24yc3jqrrQe50fA3qLSAfc+zcD2Bc3MVqoqmWfm0CfQV/VeY8FGzsmEr6gA6hqiffGaQtcB+Bt7Mzz/l2E+yvcLNQ1OxFJFpF/iMhSEcnBzVjALamAmy2fDqwQkckicrjX/hTuQzNORH4TkbsCDLEZ96EKiYiki8i/RWSFl88UIEtEklV1B654XAusFZHPRGRf71fvxM0ufhCRBSJyRahj+miHm/H6y2sfERnjbTjLwX0Ym/nr60drYJWqlvq0rcDNAMus8/k5H/fh3IOqLsUVu964P+5jgN9FpBtVK+ihjrtVVe9S1R647TKzcYVQcI9vhU/fUlxxbOMvVhC+a/I7/dxuBCAiLUTkfRFZ470W77Dna/EfoCfwgjdRCeYcVc3AzXj39YnVAThPRLaV/cPNxFvhHvMWVc33ibPKT2zftg7Acz6xtuDes228Avwibllkg4i8JiKNvd8L9Bn0VeX3WCVjx0SdKOg+UnBrhajqaer24mikqu/ivgbuAs4JMdYA3FfBE3Hr7x29dvHi/6iqZ+O++n4M/M9rz1XVIaraGbd+epuInOAn/tdAWxHpG2I+Q3DbCQ5VtxH4mAr5fKmqJ+E+VItwH1xUdZ2qXq2qrYFrgJd99zoJ0Sqgc4D7XvHG6+rldU9ZTiH4HWjnzarLtMeth1bFZNzeOmne7HUybi08G1do/fH37alKVHUTbhbeGreR+3dcsQLcXk24P46BHl91c3nMi9HLey0uxue18PZSeRb4L/CAiDQJJaiqTsYtTTztNa0C3lbVLJ9/DVX1H7hvnU1EJN0nRDt/YX1+XgVcUyFeA1X9zhv/eVU9CNgPt4x1h9fu9zNYQbXeY4HGjpWELegispeIXCgijbzZ9Cm4r1Ff++uvqtuB+4CXROQcb8abKiKniciTfn4lA/cHYDNuzfExn7HTxO2nnel9lc7BLXkgImeKSBfvw7sdt+GrtGJwVf0Vt/4/XESO82LW9x6Tv1l9Bm42ts37IJZ9/S2bmZ0tIg29nPN88jlPRNp6XbfiPkh75FOJMUArEblFROqJSIaIHOqTVw6Q530ruK7C764n8B+D6bgZ0Z3ea3EccBbwfpj5lZkMDMZ9ewG3Rj0Yty2gJMDvBMuvUiLyhIj0FJEUEcnAPf4lqroZV2DOEJETRCQV90d5F25jYsRzwb0WecB2EWnDnsXnOWCGql6F2wj4ahixnwVOEpEDcDP/s0TkFO+zV997D7dV1RW45ZcHvPf04bjXNJhXgbtFpAeAiGSKyHnezweLyKHe87cDtw2hNNhnsIIqv8cCjV3Z70VTwhZ0XGG6DliNK1RP4zbG+Vuvc7+g+gxwG26jy0bczGAw7q97RW/hvpqtwW1I+r7C/ZcAy72vttcCF3ntXXEbyvJw3wpeVtWJAVK6ifKvdNtwyxp/Aj710/dZ3PrrJi+XsT73JXmP63fc19VjKS+sBwPTRSQPt5Z5s5bvex4Sb83+JNwHYR3wK3C8d/ftuG8zubhvBSMq/PoDwJve1+nzK8Qt9GKe5j2ul4FLVXVROPn5mIwramUFfSruj/GUgL/hNmLf6+V3exXGTAdG4V6/33Az8v4AqroYN0t+Aff4zsLtClgYpVweBPrgJhKf4bYpASAiZ+N2DCh7X9wG9BG3HFkpb03+Ldza+Crct9d7KP8c3UF5vbkIOBw3GXoE954IuLyjqqOAJ4D3vc/TfNx7AqAx7n21Ffd53Ixb1oTAn0Hf2NV5jwUbOyZE/W6PM8aYmiEiI4BFqnp/pZ1NUIk8QzfG1ELeUsXeIpIkIqfiZvMfxzithGBHYRljalpL3HJPU9yS6HWq+lNsU0oMtuRijDEJwpZcjDEmQcRsyaVZhmjH5rEa3RhTFStKAh0Qa2rKppVzNqmq3+oZs4LesTnMiNqZvI0xkXb1ts3uHAImpobe0HRFoPtsycUYU6mrt22OdQomBFbQjTFBWTGPH1bQjTEBWTGPL7YfujFmD1bI45PN0I0xJkFYQTfG7MZm5/HLCrox5g9WzOObFXRjDGDFPBFYQTfGWDFPEFbQjTEmQdhui8bUYTYzTyw2QzemjrJinnisoBtTB1kxT0xW0I2pY6yYJ66QCrqILBeReSIyW0Rm+LlfROR5EVkiInNFpE/kUzXGVJcV88QWzkbR41V1U4D7TgO6ev8OBV7x/jfGGFNDIrWXy9nAW+ouUPq9iGSJSCtVXRuh+MaYarCZed0Q6hq6AuNEZKaIDPJzfxtglc/t1V7bbkRkkIjMEJEZG3PDT9YYEz4r5nVHqDP0o1R1jYjsBYwXkUWqOiXcwVT1NeA1gL6dRcP9fWNMeKyY1y0hzdBVdY33/wZgFHBIhS5rgHY+t9t6bcaYGLFiXvdUWtBFpKGIZJT9DJwMzK/QbTRwqbe3y2HAdls/N8aYmhXKkksLYJSIlPV/T1XHisi1AKr6KvA5cDqwBMgHBkYnXWNMKGx2XjdVWtBV9TfgAD/tr/r8rMANkU3NGBMuK+R1mx0pakyCsGJurKAbkwCsmBuwgm5M3LNibspYQTfGmARhBd2YOGazc+PLrlhkTByyQm78sRm6MXHGirkJxAq6MXHEirkJxgq6McYkCCvoxsQJm52bylhBNyYOWDE3obC9XIypxayQm3DYDN2YWsqKuQmXFXRjaiEr5qYqrKAbY0yCsIJuTC1js3NTVSEXdBFJFpGfRGSMn/suF5GNIjLb+3dVZNM0pm6wYm6qI5y9XG4GFgKNA9w/QlUHVz8lY+oeK+QmEkKaoYtIW+AMYGh00zGm7rFibiIl1CWXZ4E7gdIgff4iInNFZKSItPPXQUQGicgMEZmxMTfMTI0xxgRVaUEXkTOBDao6M0i3T4GOqro/MB54018nVX1NVfuqat/mGVXK15iEYrNzE0mhzNCPBPqLyHLgfaCfiLzj20FVN6vqLu/mUOCgiGZpjGfhGrjsZfjTM/DfiaAa64yqzoq5ibRKC7qq3q2qbVW1I3AhMEFVL/btIyKtfG72x208NSailm2A4x6GHlkwoAc8+xk8vcc+V/HBirmJhiqfy0VEHgJmqOpo4CYR6Q8UA1uAyyOTnjHl3p8GFxwAdx7vbu+7F/R/A+44K6ZphcUKuYmmsAq6qk4CJnk/3+fTfjdwdyQTM6YiVRApv50kEMcrLsZEnJ1t0cSNCw6Hw++HTtnQqQncPx6uOSHWWYXOZucm2qygm7ixdwv4+h54/BMYvxyuPTk+CroVclNTrKCbuNKrPbx3Y6yzCJ0Vc1OTrKAbEwVWyE0s2NkWjTEmQVhBNybCbHZuYsWWXExM/bgUHvwQcnbCWX1gyBmQFMfTDCvmJpbi+KNj4t2i3+H0J+GcfeD+4+HDaXD/yFhnVXVWzE2s2QzdxMzI6XBpH7jqUHe7bSacPBQePj+2eVWFFXNTG9gM3cRMagrkF5Xfzi+ClOTY5WNMvLMZuomZi46AQ76A5g3dkZ+PT4RbT4t1VuGxmbmpTWyGbqpk6mI44RE4+O/w4EgoLgk/Rtum8O0D7mxuE1bDwxfA4FMinWn0WDE3tY3N0E3Y5q+CP/0Tnu3vZtZ3fQ75hfDEgPBjddoLXhwY+RyjzYq5qY1shm7CNupHuPwguKgPHNER/nseDJ8W66xqjhVzU1tZQTdhq5cK2wrKb2/bCfXqyHc9K+amNqsjH0MTSZccBYd8Cbd/6pZcnp4M9/wp1lkZY0KeoYtIsoj8JCJ7XPRLROqJyAgRWSIi00WkY0SzNLVKq2yY9iBIQ5izFZ67HK7uF9ucvp4PR9wHPe+Au4ZDUXFk41+9bbPNzk2tF84M/WbctUIb+7nvSmCrqnYRkQuBJ4ALIpCfqaXaNoWnLop1Fs7s5XDhC/DaX9w3htvHwN+Gwz8viUx8K+QmXoQ0QxeRtsAZwNAAXc4G3vR+HgmcIOJ7sTBjomf0LLjyYPhTL+jdBl47Fz6YHpnYVsxNPAl1yeVZ4E6gNMD9bYBVAKpaDGwHmlbsJCKDRGSGiMzYmBt+ssb4k14PNuSV316fCw3Sqh/XirmJN5UWdBE5E9igqjOrO5iqvqaqfVW1b/OM6kYzxrnsaJjwG9zwETw9Cc5/B+49J9ZZGVPzQpmhHwn0F5HlwPtAPxF5p0KfNUA7ABFJATIBm96YPzwwEpoPgqwroe/fISc/crGbN4bpD0PTvWBVIQy7Fi49pnoxbXZu4lGlG0VV9W7gbgAROQ64XVUvrtBtNHAZMA04F5igqhrRTE3cemcq/PNz+N8lbqPlDaPguIdh1uORG6NFJjx0XvXjWCE38azKBxaJyEMi0t+7+V+gqYgsAW4D7opEciYxDJsM1x0Bp+4L3faC/5wLv66LdVZ7smJu4l1YBxap6iRgkvfzfT7tBUAE5kcmEWXUh5Vby2+vyal9p8m1Ym4SgR36b6LunxfDZwvh0uHw0Dg4a1j117gjSQbY6qBJDHbovwnqnGdg4gIoLoXMBvDjo9CmSXgx9m4BMx+FwW/Ckt/cFYkGn1y1fD76Ae4Z4a5BeuaB8Nxl1dtF0Yp57bLsp0+Z9sEDFBfm0a7nyRw94ElS0hpErH+isxm6Cejv/3PFfPQVsPBOOLA1HHxv1WJ1bQVf3gXfPVj1Yj59CVz/Ovz7T/D9YNi4CW55q2qxKhp6fZh/pUzEbVg2g0lv3kL+9lMp3DmI5bMXMHX43yLWvy6wgm4Ceu9buP5IOHZvaJ8NL/85srsbhmvsHHdEaFk+z/aHMT9VLZYMUJud1zKrFnxNSdFBwN5ANiVFZ7By3pcR618XWEE3ATWqD79uLL+9bAskx3BjZuN0l4NvPplV+HZthbx2SktvTHLKNp+WLaTWC3wEYrj96wJbQzcBvXs9HPkA/OVN6NoMXvkO+vWMXT4Dj4HXvoa/vgudsmHYDHjlivBiWDGvvfY5bADzJ/yXgtz3KSnJIjllJoef91zE+tcFEqvjf/p2Fp3xSEyGNmF4YjTcNxJKFPZrA9894Gbugbz3Ldz9PuQUwJm94ZUrXf9A7eHang9vTHH/n3oAHLJ36L8bSjG/6uUtlfYx0VO4M4dfvh9OYf522vY4gb06HhTR/olg6A1NZ6pqX3/3WUE3AX27GM57Dj6+zB3heePHkJ7hDq0Pp/+Vx4cXJxpCnZlbQTe1XbCCbksuJqDx8+CKvnBIe3f7yTPgsBfD79++WXhxIsmWWExdYhtFTUDZjWDxpvLbizdCk4bh9w83TqRYMTd1jc3Q44wqROLSIYHi+LZfcSwMmwTnvOGWSt6dBW9cFzhmoP5HdwsvTiRYMY8MVcWuVRM/bA09TgybBHe97x0h2RuGXeN244tUnEDteQXw3nduI+TJveCADsHjB+ofbpzqiEQxr+tr6Yu+fZvpHz5IcVEebfY9kX5XvExaA39XnzQ1zTaKxrnJC+HiF+HzK90Md/AoKE6Dd26ITJyr+0Umfm1hBb161v76LWNfGkhJ0WVAE5JSRtOuR2tOGvTfWKdmCF7QbQ09DkxYAJf3hV6toFE9ePhU1xapOJGKXxvYUkv1/b5oCiVFBwKtgHqUFp/E2l+mxjotEwIr6HGgeWOYv96tbwPMXwvNqnBAXKA4kYofS3Yof+TUz2hGcupGoOz5XEdaenYsUzIhso2iceCKY+HNyXDqULck8uE8GH5j5OIc0dW1n/watM+C0Qt3j19aCgWFkF7hQCBVKC6B1Gq+i6obxwp5ZHU74iIWfvMOeVveQEuzEZnP0QOGxTotE4JK19BFpD4wBaiH+wMwUlXvr9DncuAp3LVFAV5U1aHB4toaenh2FsLI6bB9J5zQA7q3iWycc/8Fn/4EJaXQMhO+uR867QUXPg+jZrj21lkw+T7X/tI4uHsEFBTBST3dent2FXZFrG6caBbzuryOXly4k2U/jaZwZw6t9z2G7JbdYp2S8VRro6i4fZYaqmqeiKQCU4GbVfV7nz6XA31VdXCoSVlBrz2e/BSeGQPfDnYz9Gs/hG+Ww9Un+G9/5Sq46t/w1SDXfuPHsK0URtwc3rhfza9enGjPzOtyQTe1V7U2iqqT591M9f7Zd9wE8tlsGHQYdGkGaSnw0Cmwdnvg9m8WwaV9ytv/70SYsjj8casTx5ZZjNlTSBtFRSRZRGYDG4DxqjrdT7e/iMhcERkpIu0CxBkkIjNEZMbG3KonbSKrVRZ8v6J8o+isNVA/NXB7i0yY9fvu7S0zwx+3KnFs46cxgYW1H7qIZAGjgBtVdb5Pe1MgT1V3icg1wAWq2i9YLFtyCV9xCewqgoYhnqWwoNAdKLRXJUVy2w7Y5zbokAWdm8KYn+GxC+Gyo117+0zokA1jF7v2a/rBCY9Ccim0zYTxv8LIW+DY7uHlU1Do4qQodMyGzxcFjxPxQl5cDLt2QcPAi/a+yy6lJcWUFO8itd7u/QO1GxMNEdsPXVW3AROBUyu0b1bVXWXjAYl/Dssa9sxn0PhKaHYt9HsENlXyDefsZyDjSmgzGFpfB4vXBu6b1RAO6gwzV8MHc9ws/NQDXPvNp8K89TBmoduAetGRUD8N+h8EP66Ej+bBPi2hR9vw86mfBhPuhRvPgGMOhO8fqsFi/o+nIL0RZDWBQ46GTZuCdp897gXeuLU9b93ehU+ePIOCvM1B242JhUoLuog092bmiEgD4CRgUYU+rXxu9gcWRjDHOm/sHHh5HCz+G+Q9Cr2awTVB9iF6ZBT8+Cv8dg8U/AP+1BNO+0fw/nOWwYp7oehJuLC36z92jjslwJK7IP9xOLKdG3fsHHehiV/ugh2PQd9WVc+nXiqceyhceZy7mHSNGDsWHn4Gim6H4odhdhJcHPhKGasWfM3sL16htOR2tPRhNq9OY+IbNwVsNyZWQpmhtwImishc4EfcGvoYEXlIRPp7fW4SkQUiMge4Cbg8OunWTdN+hYt6Q7ssSE6CO46F734N3H/8fLjy0PL+d/eDDTnh9w80brTzqSjis/PvvoP8XkAWkARFR8O0aQG7b/jtB4oLy/uXlhzNhmU/Bmw3JlYqPZRDVecCB/ppv8/n57uBuyObminTOhtGLXQH+CQluQ2VrbMC92/bBL5Ztnv/Bqnh9w80brTz8RWVDaBt2kD6Wsgvxc1pVkKLlgG7p2e1Ijntc0oKy/s3aNwiYLsxsWIn54oDu4rgtCdgR77bcDnpN/hkCBze1X//nHzoNgSapbuNjROWwL8uhUEBNlOX9W/SANo2dsX32cvcRtHTnoC8HW6j6GRv3D4do5sPRHm3xF274JgT4ee1INmgS2HcZ3D44X67D3xuLWP+9We2rtuAkI2ylNMGv0+zdvu79rXrgSyQZZw2+H1adD44oukW5G2hYMdmGjffm6QkO1tHXWdXLIpz9VLhy7tg3Dx3+tlnroR2TQP3b5wOS/8FT46Bjbkw4UI4tEvw/oP6wRNjYMVW6NISzj7IjXtsd3jsE3d+l26toPNe0c8n6rsl1qsHUyfAuHGwfTscfTS087unLQDJqfU4a8jHrF44kcKdObTscjiNst0htkkpyRQXLgeSkOQGpER4T5cx/zqHdUu+BZJJSmnA2Xd+RtM2+0V0DJM4bIZuGDMLhrwNk6+FFhnwt89g0TYYdIL/9tF3RC+X2riPeaAjRmeOeZyfvhgK3AhkAGNIa7CYS5/+OSLjRju+iU92+lwT1A9L4cIDoGVjd7Wim46CH34L3B4ttbGYB/P74qlAX6AxIMDRFO7cGjfxTeKxgm5o3wymLncHLgFM+Q3aNw3cHg3xVswBMpp1AH4FvCeIZSQl14ub+Cbx2Bp6DG3bAbkF0Cbb7f1R1f4rNsK67XBQR0ipwit62dHw0Q9w4LNu18KZq+GzO+GA9q69z3Pu5Fk/rnLtkVQjhXzbNsjNdXu3VGGj4tDrm/hddjnqr0+zYm4figqewu26uJKjBjz7x/25m1eRn7OB5u0OIMnnhdmVv52iXXk0zGyFBMmnsviB4oTbHki4/U3sWUGPAVW493/w/JfuCkEts2DMHdCmSXj9W2XBcQ+7pZH6qW4f7y/vhr6dw8snJdld43PiQli9zeXRKsudn/zTO9yl67bnw9CubuxIiXoxV4U77oIXXoDk+tC2NUz80hX2CEhJS+eiJ+by86TXKMjdxN4Hn0vTtj0pLS1l9FOns2nlLCAVSU6m/5BPaNa+Nz+MeogFk/6DJNWnYVYLzrjlAxpmtQ4rvqr6jZOe2Sqs9kDjBoofqL+pPWyjaAx8PAP+PhwmXwdN0+H+L2HGBvj8b+H1P6ADvP8t/Hiza793LLw9C1a+GN18IiXqBf3jj+HiG2HHVUA6JH8FR5TAlK/CDhXOqXR/+OQh5o57G3eMXTowltT68zj20meY9MbdFBdeDaQjSePZq1MhZ932UVi5LJ/zmd84vU64Mqz2QOMGih9uniY6bKNoLTNrGZzbC5o1dBsbrzkcZi0Pv/+3v8Alfcrbrz8CNucFjhOpfCKhRpZaZs6EHfsCDQGBkkNgzuyoD7t+yXSgT/m4HEFRwXY2rZxDcWH3P9q19FC2rJkXdvxAccJtDze+qf2soMdAp73cwTiFxe72+F+gU/Pw+3dp6c6AWNY+brFbkol2PtVVYxtAO3eGhqsA74HxC7TrUKVQQ69vwtDrA6yJVZDZojOweLdxk1Lq07hZB1LSVu7W3ig78P7vgQSKE257uPFN7Wdr6DFwyVHw6Uzo9U93+tmFG+CLIMsbZf17PgNtMmHxRte/Wyvofjvs/bhrn78Ohl1T/nvrtrnT1XZqvvv1OueucBeqOHofd53QcPOpjhrdm+WSS2DERzD1BUjOhqQN8O74qA97xPlPsWJuX3bteAxoBGziuEtfpWPvM1k68zPWL30eScpGZAPHXf5hpfHWLJpM3pZVdDrwLNIaZNLlkAv8xslutS9LZ37G2l+fBhqQlLyD4y7/+I/2UMcNFN/UfraGHiOlpTB9qdvYeHBnaJoRuK8q3PY2DJ0IDeu5Iy/H3w0dmrtTeg+bAhu2wwWHQddWrv+Qd+D1yZCd7k5T+8Xf3NGch98H81ZD43pQUOz2WjmyW3j5VEXMdkssLYXp090RoQcfDE2rt99lKGvpqsq3w+9i8bR3EalP/UYZnDVkNBlN26GlpWxYPpPCnTk073Ag9RsFnvWXlJTw7t96UbhzC+6SvoX0u+rfdD6wv984rn9Pb1/1yvsHfQxh9jc1p1rXFI2Wul7QwzFyOjw80m20zGoAj30Nk1bCuHvC69+rPXz6I/xws2t/5Ct49XtY/VJ084/HfcwDCaWgL5s1mslv3+dtVGyAJE2geYcc+t8+OqyxvnxlAKvmzwBuBhoAX4F8w1UvropIfxOfbKNonJu7Es7p4YowwGV9YW6Qz2ig/j/+5s51XtY+8GDYuiOqqSdUMQ/V5jXzKS7shiuqoKUHsXVt+JcI2Lx6Pu5Ep94LxsGgRRHrbxKPFfQ40KUlfLUECrzP5mcLoUuQs7QG6r9va3flobL2T3+GjBAvZ1cViVjMQ9kwmrlXZ1LSlgNlxXQRGU07hj1W4+YdgZ994vxMsM1e4fY3iafSV1tE6gNTcItyKcBIVb2/Qp96wFu4S89txl1TdHnEs41Tyza4jZPdWrn17MraK7roSBg7G/Z9Clo3hlXbYexdlfff+3Fo0hC27nQHHHVtCT3vgA6PupNt/bYZ3r0h/HxC4beYL1sGOTnQrRvUD+EvyZQpsG4dnHwyZGXVXJxA/UO098HnsXz2ONYs+heSlEVS8naOv3zUH/cvnfEReVvW0OXQ82mYWf6XOXfTCgoLcsls0YWU1PqcfP0I3rljP0qLH8btz76dw899OIT+j+JO5rWZw899qNJ8K8aprD1SYjVuIgvlz/cuoJ+q5olIKjBVRL5Q1e99+lwJbFXVLiJyIfAEcEEU8o0rqnD9MPjwB2jeCApLXSHuvJf/9kCXYEtOgncHw5wVsH0nHNjBbRgNRICf10DuLkhJckV6/XbYrw0cvx8MnwYb8tzYPdsFzrMql4TzW8hVYeAgGPEBpDaGjCSY8jXsvbf/IKWlsE8vWLoUSIeknTD+Mzj++OjG6dTJf/9+Qa93voekpGROHPRftqyeT2FBDk3b9iKtQWNKSkp4+47uFO/KAxrw4yePceylz9HlkPOY8vat/DZrNEnJGaTWE868dRSNmnYgPbMleZtXACUgKWS37o6q+u3fuHknLvvnEuZ99QL529fS/egryG7VLWCegeJkNOsYMH4kxGrcuiCUKxYpUHa4Sqr3r+Kn9mzgAe/nkcCLIiIaqy2utcSI7+GHX2DpXW5p45lJMOg/cPUJ/tu/vjdwLBHo3TG0cW95Gwp3wZr/c/GfmgiXvATPXAIzlpS3VyefsIwYASO/goLboaA+7JgCAy6H6d8EeAC3wNJNwL1AfSidBP3Ph6EvRjfOoQf6758X/ALS/ogITdv12q1t3CsXUrwruTw+k5j89hCSklNY9tMUSopup6SoPkW7JjPx9cE079iLvM3byvvrJMa9egVHX/SE3/5n3/kZycnJ9D7llpBy/G3mKL9xeva7MmD8SIjVuHVBSGvoIpIsIrOBDbhrik6v0KUNsApAVYuB7UCUzssXP35eDWd2L1+nvvBAWLAmcHukzF4B5+5fHn9AH9iWH/18Aq6ZL1gAO7rgihhQegAsCrKR8KefgP3L+3Mg7MiNfpxA/SNk69rFe8bXIrauXURxYdfydu3NtvW/sHnVvD36FxfmBewffj7+40Qqfm0bty4IqaCraomq9gbaAoeISM+qDCYig0RkhojM2Bi5z0mttW9r+GIx5Be62x/Ng31bBW6PlF7tYNT88vgfzoXGDaKbT9ANoN27Q8PfAG8AmQ9d9wncf//9gfnl/ZkH6Y2iHydQ/wpCPWK0oqyWXV1M3/ikkNVyH1LSlu6WT+PmXWjStsce+SSnNgzYP/x8/MeJVPzaNm5dEPZ+6CJyH5Cvqk/7tH0JPKCq00QkBVgHNA+25FIX9kMvLYWr/wNfzHEbIbcVuEu3dWkBV/0HvvjJrVnnFMK4u2GfCBX14mLofTes2erOz7IuF0beAif1DJyPv/ZQ86l0b5bSUrh4IHw8BlIzoX4RfPM17BOgGBcXw977wcrVQEOQXPjiEzjpJLjochg1GpLToaHA1IlVj/Pxp5CcAeml7pJ0nTv773/KKW47wMKFbiNqr15c9eYuwK0Hb1u3mKKCXLJb70eqdwk6f+0lhYW8dWd3Sop24TZy5nL0RU+xz2EDmPjGYFbM+RJJyiAlrZizbvuYjKYdGfHAEezY+vsf+Zx6/Tu02fc413/uOJKSM0lOLeSsW0eR2SK84qelpX7jNG7eOWD8QI832uOactW6pqiINAeKVHWbiDQATsJt9PQ1GrgMmAacC0yo6+vn4E69PXQQ/LrOHYHZoy2k13P1raQESoGiEihVVy8iJSUF5j4B4+e7w//P6A3NGrv7/OUTrL0yIe2amJQE774Bv/7qjtjs0QPSg2zVTUqCQw5ye5okAQ2zoWNHd19JCUgySJrbxzrYE5eSAssWwfjxLtYZZ0CzZt4LUHaekhIXQzXwuKWl8NdLYMyXkJIJ9Xax7boPyWy+NxNev46V8ya4ApRSwJm3jQrYntWiK5c+8wtLpg8nb8tquh1xMY2atEVLSyktLUZRoARVRVGSUlK44KHv+X3RJPJz1tO+58nUb+RWMo8f+BI5G5ZSWJBDdqt9SUkL8nwGIElJAeP4a9fS0oCPK5rjmtBVOkMXkf2BN4Fk3Nv8f6r6kIg8BMxQ1dHero1v445q2AJcqKpBL1ZWF2bogbz7LbzwGUy4BtLT4KVv4X8/w+T7Yp1Z6KK6j/m778I198OOK4A0kO+g91oYMth/+6xp0Y3vp71pm9X0OuFKpg5/kuLCK0Nq/9PdY/2ms+SHD8LqHyvxkmeiq9YMXVXn4gp1xfb7fH4uAM6rTpJ1yeLf4ZR9XDEHOKcnPPx1bHMKR9QPGFq0CHZ0ArwnSHvA0imB26Md30/75pwpbFv/K8WFnXdrz9k0OWB7IOH2j5V4ybMusyNFY6BHW/h0IeQUuNvvzYKebWObU6hq5OjPnj2h4RLAe4KSZkP3/QK3Rzt+gPbs1t1JSfv1j3aR2WS17BawPZBw+8dKvORZl9lxwTFw/mHwzSLo/Dg0a+TW0oMd+Vlb1Nih/OefD19OgHf/AckN3Mln3pvkDvz58mt4+zFIqg/ZjVw7uDXwWbPcRssDDwx+hOf558O4ifDeU5CaAY1T4T3vwKKxX8M7j0JSGmRnwHtTvHH3zKfzF5ms/vkblv74OJLUgLQG6Rw/8GMymnZg1YIpLP3xUUTSSEvP4PiBo700lc2r5lBYkEvTtvtTLz2Tzn3OYc3CqSz98Ul3QE39VI4fGPzqQP7iRFuwPCOVTyweVyKxgh4DIvDiQPhbf7cRsmtLqJca66yCq9HzspSWwsaNkNIQkjKhYDvk50NREXw2FopTgAawYT3MmQMdOsA558HEaZCcCSnbYPJXbmbt98EI/PdVeODvbiNt165Qrx4UFsLnY6E4FWgEGzaWx/eTj2oGBXmbkaRGSFJjSoq3U1y4k5KSIlYvmICWpqI0oiB3I5tXL6BRk3aM//cVrP3lRyQpk6SkbZxx60c0ad2dYy5+hj5n3Ebhzhwym3cmOTXwVunS0pKAcaJJRPzmGal8YvW4EokV9Bhq19T9MxW88w5MnA/5twIpID/AgIFwaG/YUArc49r1exhwBbz6rOu/4+bd+8/9Mfg47dq5f2VuuCF4/Ar5LOl9OWt/WURJkdfOD0x8/Uaad+xBQZ6Wx+F7Jr5+I0f99VHW/rKI4sJbduv/l7+7a5w2ym4D2ZVfwHrJD/8LGifaKuYZqXxi/bgSga2hm6BkgNb8WROXLIEdHfljvqHdYMUyt3GS7uXtdIeC/MD9wxVm/Ckd1lFc2Mmnfzfytqxg+7ole8QpLd5JzsZlfvuHK1JxIiVRH1c8soJuAorZ6W9794aGi4F8QCF5BvTsBYcdBvxU3s50aJQZuH+4wo3fuzcpaYv+aJekGWS33o+9Oh20R5yUeo1p2ran3/7hilScSEnUxxWPbMnF+BXS0Z/ffec2Qh5yiDtgJ1L+/GeY9A3829sIuVcTGP41tG3rNmbOfRio596948a7Qvz1ZHj1EZAUl8vwqeHn/8QTgeNPmgqvPQmp6V4+46BdO7oeNp5FU/9BUlJ9GjTOpt/AUaRntWb1wqls/d3FkSTltMEfsVenvqz9dTqLpj5BUnJDGmRk0W/gyLCfno69z4pInEiJVD617XHFI7sEndlDpcW8uBhO6w/fz4OkLJB1MHGc27skEsriT5sN0giStsCk8eXxFy6EtWvhiCPcecy3bYPsVriTOmUCv8Pga+CFF6qWf8X4ZTZudH8AOnRwR6EWF9O652msXzYfIQORzZxx64c0ab0fY1+6iHW/zUVogEgOZ972Ec3a7Q/AztxNFBXk0qhJO5KSqz6nilScSEnUx1Xb2DVFTchCWmYZNgxufBLyB+IOIJ4B+/0CC2ZFJolw43ftCkt2ATeU9+cT0J3RzX/YMFKue4Liwiv+iJPVaiG9+l3FtA9e3KP93HsnhhffGD/smqKmUmFt/Fy2DPLb44oVQBdYHcELEYcbf/0GoNvu/SmJXPwgcYoLO+wWZ8fWNeRuXuG33Zhos4Juwt/4efDB0PBn3HVPFJKnR265pSrxe/UEZpb35zuCbh6KVP4V4kjSdJq225/mHQ4kJW3BHu3GRJstUNVxVdqTpX9/uGE6/OtJSE6Djh3gvS+qlkBJCUyY4A7wOfJIaNUqeHx//b/9Fho2gfxH+OMt/e6wquXvL34IcZJJo1GTthx/+QgaZrViv2NnMn/CE0hSvT/aTeVKS0v4ffEUinbm0mLvQ0jPbBnrlOKKraHXYdXeLTEnB/LyoGVLd+rZcBUWQr9TYc4ykCxgJXz1hdvrxF/8QP1793btsxaDpkPyJpjwZXmcUPOvLJ8gcf764irSG7dAfJ6Hwp05FO3asUe78a+kuJDPnzufzWtWIpINuoLTbhrBXh0PinVqtUq1zrZoTECNG7t/VfXmm/DTesi/Drf6NxsuvRoWzfEfP1D/IYNd+86b/ccJNf/K8gkSZ/g9Pbjq5S27Nac1aExag2o8P3XMr9PfZ/PqTRQXXk/Z8z/5rVs5774qnFGzjrJpQx0Vs4OGfK1cCfltKH8bdoS1v4ffP9w4kcrHRFTeltUUF7bF9/nP374ulinFHSvodUxMDuUP5PDDoeF83DXFSyHlOzg4yPJGoP7hxolUPiaiWnQ6mJS0eZQ9/5L0Lc079Il1WnEllEvQtQPeAlrgdiF4TVWfq9DnOOAToOwEGh+p6kMRzdRUmwxQd8bCzz9368fHHgvt2wf/pXD7h+P002HItfDoo0AS7LMvvPd+4HFPPx2GXAOPPuL17w7vjYO99oI7r4dHHnGXp9uvZ3mccPMJN05+vuu/ZQvrG/2JFp0PDn/cIEpLilg1fzyFBbm06nokjZrEyYnzq6Bdz5PY/6QrmP3FUyBJZLXqzvED34t1WnEllEvQtQJaqeosEcnA7R92jqr+7NPnOOB2VT0z1IFto2jNkgEKu3bBUf1g0QYgG1gCYz91e3P4E27/cJXFX7geaAyy3MXv29f/uL7tmgWydPd8du1yBTY7u/p5hRInJwdadYT8+kAT4BeOuOAx9jvmiuqN7ykp2sWn/zyHbes3U/Y8nHrDe7Tc+9CIxK+tSop2UVy0k3rpWbFOpVaq7iXo1gJrvZ9zRWQh0Ab4OegvmlrjjyWW11+Hn3Mg/2rcats8uPwa+HW+/18Mt3+4/og/aPf4Qwb7HzdQe1k+9eq5f9UVapxrr4X8JkB5/tM+eDBiBf2X799j69odlBSVx5/y9hDOf6CS89TEueTUekHPB28CC2sNXUQ64q4vOt3P3YeLyBwR+UJEegT4/UEiMkNEZmzMDT9ZE77d1st//x3yW1L+srdzF4kIJNz+4QoUP9z2WFm9Gui4Wz5aWhix8Pnb1lFS1Gq3+DtzN0Qsvkk8IRd0EWkEfAjcoqo5Fe6eBXRQ1QOAF4CP/cVQ1ddUta+q9m2eUcWMTUj8bvw86ihInwdsBUohdYo7AVUg4fYPV6D44bbHymmnAT+U58PX1GsYubNOtuhyGClpc/+In5Q8OeJr9CaxhHRgkYikAmOAL1X1nyH0Xw70VdVNgfrYGnr0BN2L5fEn4f/udaePPeAg+OpzaBrksklPPwP3/N31P/gIGPNh8P7hevhReOABd03QfXvCN1+7+IHGjXY+4TrzbPhsjPu5URPOu+1zMlvsHbHwc8e/zIxPH0FLS2ne8RBOvvYN6jdqErH4Jv5U62yLIiLAm8AWVb0lQJ+WwHpVVRE5BBiJm7EHDG4FPTqCFvOdO+HQo+G3PCjNBPkFxnwExx8fPGhJiTuKskGDyCa7ZQu07gS7MnEbFRfCM4/DbbcFHzda+VRVYaE74rRJkz0OLoqE0tISSosLSUmrJY/XxFR1z7Z4JHAJ0E9EZnv/TheRa0XkWq/PucB8EZkDPA9cGKyYmxgZNgyWFMKOK2HneZD/J7jqhsp/Lzk5OsXz2mthVwvgRuBi4CL42/2VjxutfKoqLQ2auFnz0OsjP3tOSkq2Ym5CEspeLlMBqaTPi8CLkUrKVE2lBwytXw8FLSh/OVvDpo3RTiuwdeuA9rvnUxy5jYrG1DV2pGiCCOnoz+OOgwZzgA1AEaRNcAftxMrZZwPfl+fDWGhhZ9czpqrs5Fy1TP4uGPE95OyEE3tCj0oODAzrMP5+/eCpB+H2O6GwAI46Ed4a6g2cDyNGuINlTjwRevjd8zSyhgyBadPhw38CpZDRDKb/GP1xIykWz5sxAdjpc2uRHQVwzEPQIh06ZcP/5sI7N8ApAa6NUOVzsqi6vUSSvSvq7NgBBx0Oq4HiLEieCx+NgFNOqVr8UJWNu7LUjZs6v2bGjZQgz1s0No4aA3b63LgxbDJ0aAwfXgoicNZ+cPs7cMqTe/at1gm2RMqLObiNpSuSoWAAbj17H7j2Jli2uOpjhOKPcS9x4xbtWzPjRkqsnjdjArA19FpkUy70aOHqLUCPlrA5b89+ET9b4saNsKsZ5RsnW8LWrZEdozaNGynxnr9JOFbQa5ETesDrM2D2Gti+E+75wq2j+4rKqW9PPBEa/ASsAXZCvXFw4gmRH6e2jBsp8Z6/SThW0GuRY7rDo+fDacOg1UNQmAwvDXT3RfU85sccAy8+BZnvQOqjcGJbeP216IxVG8YFd16YCy+EU0+F4cMr75+bCy+/DP/4B/z0k2uLZf7G+GEbReNErbkoRSJYvRo6dYPiDkAz4Af4vzvhoQCn8M/Jgd6HwLp0KMqEtDkw4i04s/KzRdvGURNp1T1S1MSYFfMIu+kmKO4EXAH0By6Dx4Kcouj112FtQ9g5AIrPgPzz4PpbayhZY0JnBb2Ws2IeBZs34y7AVaYZlBQH7r9lC+zyPaS/GeRuj1JyxlSdFfRazIp5lAwYAHwHLAdygE+CX1rvlFOg/qzy/vXHurV3Y2oZ2w+9lrJiHkXXXAMLFsCL/wEthrYd4MfvAvc/4ggY9hLcfAfsyIXTz4Chr9RcvsaEyDaK1jJWyBOPbRg1kWQbReOEFXNjTHVYQa8lrJgbY6rLCnotYMXcGBMJlRZ0EWknIhNF5GcRWSAiN/vpIyLyvIgsEZG5ItInOukmnlpTzDduhIcfhtuGwKRJsc4moUTjKkbG+BPKXi7FwBBVnSUiGcBMERmvqj/79DkN6Or9OxR4xfvfxIPNm2H/vrC5jTsS8t9vwn+e93bvM8bEi0pn6Kq6VlVneT/nAguBNhW6nQ28pc73QJaItIp4tgkkqudmCdcbb8DWllD0Z+AEyL8A7rg31lkZY8IU1hq6iHQEDgSmV7irDbDK5/Zq9iz6iMggEZkhIjM25oaZaQKpNYW8TF4eFDXyaciEnTtilo4xpmpCLugi0gj4ELhFVXOqMpiqvqaqfVW1b/OMqkSIf7WumAOcdRbUm4X78rUeGoyGc/8S66yMMWEKqaCLSCqumL+rqh/56bIGaOdzu63XZnzUymIO0KcPfDQc9pkBLT+AgSfAi8/GOquEYhtGTU2odKOoiAjwX2ChqgY6Jd1oYLCIvI/bGLpdVddGLs34V2uLeZlTT4XFdn4SY+JZKHu5HAlcAswTkdle2z1AewBVfRX4HDgdWALkAwMjnmmcqvWF3BiTMCot6Ko6lfKLJgbqo8ANkUoqUVgxN8bUJDtSNEqsmBtjapoV9CiwYm78sQ2jJtqsoBtjTIKwgh5hNjs3xsSKXbEoQqyQG2NizWboEWDF3IRq6PVNbC3dRI0V9GqyYm6MqS2soFeDFXNjTG1iBb2KrJgbY2ob2ygaJivkxpjaymboYbBibiLFNoyaaLCCHiIr5saY2s4KujHGJAgr6CGw2bkxJh5YQa+EFXNjTLywgh6ADFAr5iaqbMOoibRKC7qIDBORDSIyP8D9x4nIdhGZ7f27L/Jp1hwr5MaYeBXKfuhvAC8CbwXp842qnhmRjGLICrkxJp5VOkNX1SnAlhrIJaasmJtYsGUXE0mROlL0cBGZA/wO3K6qC/x1EpFBwCCA9s0iNHI1WSE3xiSKSGwUnQV0UNUDgBeAjwN1VNXXVLWvqvZtnhGBkavJirkxJpFUu6Crao6q5nk/fw6kikgtmX8bY0zdUe2CLiItRUS8nw/xYm6ubtxos9m5MSbRhLLb4nBgGtBNRFaLyJUicq2IXOt1OReY762hPw9cqKq1ulpaMTe1iW0YNZFS6UZRVf1rJfe/iNutMS5YMTfGJKo6cz50K+TGmERXJw79t2JujKkLEr6gWzE3xtQVCV3QrZibeDH0+ia2cdRUW8IWdCvmxpi6JuE2ilohN8bUVQk7QzfGmLomoQq6zc5NvLN1dFMdCVPQrZgbY+q6hCjoVsyNMSYBCroVc2OMceJ2Lxcr5MYYs7u4nKFbMTeJzDaMmqqKu4JuxdwYY/yLq4JuxdwYYwKLm4JuxdwYY4IL5YpFw0Rkg4jMD3C/iMjzIrJEROaKSJ/Ip2mMMaYyoczQ3wBODXL/aUBX798g4JXqp1VOBqjNzk2dYxtGTVVUWtBVdQqwJUiXs4G31PkeyBKRVpFIzgq5McaELhL7obcBVvncXu21ra3YUUQG4WbxAHlyEYuDRr5IIpBetTUDNsU6iRpkj7eWGBqdsLX28UZJIj7eDoHuqNEDi1T1NeC1mhyzukRkhqr2jXUeNcUeb2Kzx5vYIrGXyxqgnc/ttl6bMcaYGhSJgj4auNTb2+UwYLuq7rHcYowxJroqXXIRkeHAcUAzEVkN3A+kAqjqq8DnwOnAEiAfGBitZGMkrpaIIsAeb2Kzx5vARNX2JDHGmEQQN0eKGmOMCc4KujHGJAgr6JUQkWQR+UlExsQ6l2gTkeUiMk9EZovIjFjnE20ikiUiI0VkkYgsFJHDY51TtIhIN+91LfuXIyK3xDqvaBKRW0VkgYjMF5HhIlI/1jlFm62hV0JEbgP6Ao1V9cxY5xNNIrIc6KuqiXYghl8i8ibwjaoOFZE0IF1Vt8U4ragTkWTcrsWHquqKWOcTDSLSBpgK7KeqO0Xkf8DnqvpGbDOLLpuhByEibYEziNpBeyZWRCQTOAb4L4CqFtaFYu45AViaqMXcRwrQQERSgHTg9xjnE3VW0IN7FrgTKI1xHjVFgXEiMtM7TUMi6wRsBF73ltSGikjDWCdVQy4Ehsc6iWhS1TXA08BK3GlItqvquNhmFX1W0AMQkTOBDao6M9a51KCjVLUP7gyaN4jIMbFOKIpSgD7AK6p6ILADuCu2KUWft7TUH/gg1rlEk4hk404c2AloDTQUkYtjm1X0WUEP7Eigv7eu/D7QT0TeiW1K0eXNalDVDcAo4JDYZhRVq4HVqjrduz0SV+AT3WnALFVdH+tEouxEYJmqblTVIuAj4IgY5xR1VtADUNW7VbWtqnbEfUWdoKoJ+xdeRBqKSEbZz8DJgN+LmiQCVV0HrBKRbl7TCcDPMUyppvyVBF9u8awEDhORdBER3Ou7MMY5RV2Nnm3R1GotgFHuvU8K8J6qjo1tSlF3I/CutwzxG4l32ordeH+oTwKuiXUu0aaq00VkJDALKAZ+og6cBsB2WzTGmARhSy7GGJMgrKAbY0yCsIJujDEJwgq6McYkCCvoxhiTIKygG2NMgrCCbowxCeL/Aas3XfEd8HzlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# meshsize\n",
    "h = 0.02\n",
    "x_min, x_max = X[:,0].min()-1, X[:,0].max() + 1\n",
    "y_min, y_max = X[:, 1].min()-1, X[:,1].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max,h), np.arange(y_min, y_max,h))\n",
    "\n",
    "Z = sr.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, z, cmap = cmap_light)\n",
    "plt.scatter(X[:,0], X[:,1], c = y, cmap = cmap_bold, edgecolor = 'k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(f'3-Class Classification with Softmax Regressions')\n",
    "\n",
    "# everything is similar to Logistic regression, Binomial Case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "56603baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z # ?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ebcd4f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 2, 2, 2],\n",
       "       [0, 0, 0, ..., 2, 2, 2],\n",
       "       [0, 0, 0, ..., 2, 2, 2],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 2, 2, 2],\n",
       "       [0, 0, 0, ..., 2, 2, 2],\n",
       "       [0, 0, 0, ..., 2, 2, 2]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d06e7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a56f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ebe2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507249f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b41e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd1ed5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff8b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc59de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9efd29e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776220f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13517b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fddd6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d787aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a300a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
